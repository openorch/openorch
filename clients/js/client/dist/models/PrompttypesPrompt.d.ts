/**
 * Singulatron
 * Run and develop self-hosted AI apps. Your programmable in-house GPT. The Firebase for the AI age.
 *
 * The version of the OpenAPI document: 0.2
 * Contact: sales@singulatron.com
 *
 * NOTE: This class is auto generated by OpenAPI Generator (https://openapi-generator.tech).
 * https://openapi-generator.tech
 * Do not edit the class manually.
 */
import type { PrompttypesPromptStatus } from './PrompttypesPromptStatus';
/**
 *
 * @export
 * @interface PrompttypesPrompt
 */
export interface PrompttypesPrompt {
    /**
     * CreatedAt is the time of the prompt creation.
     * @type {string}
     * @memberof PrompttypesPrompt
     */
    createdAt?: string;
    /**
     * Error that arose during prompt execution, if any.
     * @type {string}
     * @memberof PrompttypesPrompt
     */
    error?: string;
    /**
     * Id is the unique ID of the prompt.
     * @type {string}
     * @memberof PrompttypesPrompt
     */
    id?: string;
    /**
     * LastRun is the time of the last prompt run.
     * @type {string}
     * @memberof PrompttypesPrompt
     */
    lastRun?: string;
    /**
     * MaxRetries specified how many times the system should retry a prompt when it keeps erroring.
     * @type {number}
     * @memberof PrompttypesPrompt
     */
    maxRetries?: number;
    /**
     * ModelId is just the Singulatron internal ID of the model.
     * @type {string}
     * @memberof PrompttypesPrompt
     */
    modelId?: string;
    /**
     * Prompt is the message itself eg. "What's a banana?
     * @type {string}
     * @memberof PrompttypesPrompt
     */
    prompt: string;
    /**
     * RunCount is the number of times the prompt was retried due to errors
     * @type {number}
     * @memberof PrompttypesPrompt
     */
    runCount?: number;
    /**
     * Status of the prompt.
     * @type {PrompttypesPromptStatus}
     * @memberof PrompttypesPrompt
     */
    status?: PrompttypesPromptStatus;
    /**
     * Sync drives whether prompt add request should wait and hang until
     * the prompt is done executing. By default the prompt just gets put on a queue
     * and the client will just subscribe to a Thread Stream.
     * For quick and dirty scripting however it's often times easier to do things syncronously.
     * In those cases set Sync to true.
     * @type {boolean}
     * @memberof PrompttypesPrompt
     */
    sync?: boolean;
    /**
     * Template of the prompt. Optional. If not present it's derived from ModelId.
     * @type {string}
     * @memberof PrompttypesPrompt
     */
    template?: string;
    /**
     * ThreadId is the ID of the thread a prompt belongs to.
     * Clients subscribe to Thread Streams to see the answer to a prompt,
     * or set `prompt.sync` to true for a blocking answer.
     * @type {string}
     * @memberof PrompttypesPrompt
     */
    threadId?: string;
    /**
     * UpdatedAt is the last time the prompt was updated.
     * @type {string}
     * @memberof PrompttypesPrompt
     */
    updatedAt?: string;
    /**
     * UserId contains the ID of the user who submitted the prompt.
     * @type {string}
     * @memberof PrompttypesPrompt
     */
    userId?: string;
}
/**
 * Check if a given object implements the PrompttypesPrompt interface.
 */
export declare function instanceOfPrompttypesPrompt(value: object): value is PrompttypesPrompt;
export declare function PrompttypesPromptFromJSON(json: any): PrompttypesPrompt;
export declare function PrompttypesPromptFromJSONTyped(json: any, ignoreDiscriminator: boolean): PrompttypesPrompt;
export declare function PrompttypesPromptToJSON(value?: PrompttypesPrompt | null): any;
