---
id: prompt
title: "Prompt an AI"
description: "Sends a prompt and waits for a response if sync is true. If sync is false, adds the prompt to the queue and returns immediately."
sidebar_label: "Prompt an AI"
hide_title: true
hide_table_of_contents: true
api: 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
sidebar_class_name: "post api-method"
info_path: docs/openorch/openorch
custom_edit_url: null
---

import MethodEndpoint from "@theme/ApiExplorer/MethodEndpoint";
import ParamsDetails from "@theme/ParamsDetails";
import RequestSchema from "@theme/RequestSchema";
import StatusCodes from "@theme/StatusCodes";
import OperationTabs from "@theme/OperationTabs";
import TabItem from "@theme/TabItem";
import Heading from "@theme/Heading";

<Heading
  as={"h1"}
  className={"openapi__heading"}
  children={"Prompt an AI"}
>
</Heading>

<MethodEndpoint
  method={"post"}
  path={"/prompt-svc/prompt"}
  context={"endpoint"}
>
  
</MethodEndpoint>



Sends a prompt and waits for a response if sync is true. If sync is false, adds the prompt to the queue and returns immediately.

Prompts can be used for `text-to-text`, `text-to-image`, `image-to-image`, and other types of generation.
If no model ID is specified, the default model will be used (see `Model Svc` for details). The default model may or may not support the requested generation type.

**Prompting Modes**
- **High-Level Parameters**: Uses predefined parameters relevant to `text-to-image`, `image-to-image`, etc. This mode abstracts away the underlying engine (e.g., LLaMA, Stable Diffusion) and focuses on functionality.
- **Engine-Specific Parameters**: Uses `engineParameters` to directly specify an AI engine, exposing all available parameters for fine-tuned control.

**Permissions Required:** `prompt-svc:prompt:create`

<Heading
  id={"request"}
  as={"h2"}
  className={"openapi-tabs__heading"}
  children={"Request"}
>
</Heading>

<ParamsDetails
  parameters={undefined}
>
  
</ParamsDetails>

<RequestSchema
  title={"Body"}
  body={{"content":{"application/json":{"schema":{"properties":{"engineParameters":{"allOf":[{"properties":{"llamaCppParameters":{"properties":{"template":{"description":"Template of the prompt. Optional. If not present it's derived from ModelId.","example":"[INST]{prompt}[/INST]","type":"string"}},"type":"object"},"stableDiffusion":{"properties":{"txt2Img":{"allOf":[{"properties":{"alwayson_scripts":{"additionalProperties":{"type":"string"},"type":"object"},"batch_size":{"type":"integer"},"cfg_scale":{"type":"number"},"comments":{"additionalProperties":{"type":"string"},"type":"object"},"denoising_strength":{"type":"number"},"disable_extra_networks":{"type":"boolean"},"do_not_save_grid":{"type":"boolean"},"do_not_save_samples":{"type":"boolean"},"enable_hr":{"type":"boolean"},"eta":{"type":"number"},"firstpass_image":{"type":"string"},"firstphase_height":{"type":"integer"},"firstphase_width":{"type":"integer"},"force_task_id":{"type":"string"},"height":{"type":"integer"},"hr_checkpoint_name":{"type":"string"},"hr_negative_prompt":{"type":"string"},"hr_prompt":{"type":"string"},"hr_resize_x":{"type":"integer"},"hr_resize_y":{"type":"integer"},"hr_sampler_name":{"type":"string"},"hr_scale":{"type":"number"},"hr_scheduler":{"type":"string"},"hr_second_pass_steps":{"type":"integer"},"hr_upscaler":{"type":"string"},"infotext":{"type":"string"},"n_iter":{"type":"integer"},"negative_prompt":{"type":"string"},"override_settings":{"additionalProperties":{"type":"string"},"type":"object"},"override_settings_restore_afterwards":{"type":"boolean"},"prompt":{"type":"string"},"refiner_checkpoint":{"type":"string"},"refiner_switch_at":{"type":"number"},"restore_faces":{"type":"boolean"},"s_churn":{"type":"number"},"s_min_uncond":{"type":"number"},"s_noise":{"type":"number"},"s_tmax":{"type":"number"},"s_tmin":{"type":"number"},"sampler_index":{"type":"string"},"sampler_name":{"type":"string"},"save_images":{"type":"boolean"},"scheduler":{"type":"string"},"script_args":{"items":{"type":"string"},"type":"array"},"script_name":{"type":"string"},"seed":{"type":"integer"},"seed_resize_from_h":{"type":"integer"},"seed_resize_from_w":{"type":"integer"},"send_images":{"type":"boolean"},"steps":{"type":"integer"},"styles":{"items":{"type":"string"},"type":"array"},"subseed":{"type":"integer"},"subseed_strength":{"type":"number"},"tiling":{"type":"boolean"},"width":{"type":"integer"}},"type":"object"}],"description":"Text to image parameters"}},"type":"object"}},"type":"object"}],"description":"AI engine/platform (eg. Llama, Stable Diffusion) specific parameters"},"id":{"description":"Id is the unique ID of the prompt.","type":"string"},"maxRetries":{"description":"MaxRetries specified how many times the system should retry a prompt when it keeps erroring.","example":10,"type":"integer"},"modelId":{"description":"ModelId is just the OpenOrch internal ID of the model.","example":"huggingface/TheBloke/mistral-7b-instruct-v0.2.Q3_K_S.gguf","type":"string"},"parameters":{"allOf":[{"properties":{"textToImage":{"properties":{"aspectRatio":{"description":"Alternative way to specify dimensions (e.g., \"16:9\", \"1:1\").","type":"string"},"batchSize":{"description":"Number of images to generate per batch.","type":"integer"},"denoisingStrength":{"description":"Controls how much variation is introduced in image modifications.","type":"number"},"enableUpscaling":{"description":"Whether to apply AI-based upscaling.","type":"boolean"},"format":{"description":"Output format for the generated image (png, jpg, webp, etc.).","type":"string"},"guidanceScale":{"description":"How closely the output should follow the prompt.","type":"number"},"height":{"type":"integer"},"negativePrompt":{"description":"A negative prompt to specify what should be avoided in the image.","type":"string"},"numIterations":{"description":"Number of batches to generate.","type":"integer"},"prompt":{"description":"The primary prompt for generating the image.\nDefaults to the top-level prompt if not specified.\nIf both are provided (which should be avoided), this field takes precedence.","type":"string"},"qualityPreset":{"description":"Preset quality settings (e.g., Low, Medium, High, Ultra).","type":"string"},"restoreFaces":{"description":"Whether to enhance facial details for portraits.","type":"boolean"},"scheduler":{"description":"Specifies the sampling method used during generation.","type":"string"},"seed":{"description":"Optional seed for reproducibility. If not set, a random seed is used.","type":"integer"},"steps":{"description":"Number of inference steps for image generation.","type":"integer"},"styles":{"description":"List of artistic styles or themes to apply.","items":{"type":"string"},"type":"array"},"width":{"description":"Image dimensions (width and height in pixels).","type":"integer"}},"type":"object"},"textToText":{"properties":{"template":{"description":"Template of the prompt. Optional. If not present it's derived from ModelId.","example":"[INST]{prompt}[/INST]","type":"string"}},"type":"object"}},"type":"object"}],"description":"AI engine/platform (eg. Llama, Stable Diffusion) agnostic parameters.\nUse these high level parameters when you don't care about the actual engine, only\nthe functionality (eg. text to image, image to image) it provides."},"prompt":{"description":"Prompt is the message itself eg. \"What's a banana?","example":"What's a banana?","type":"string"},"sync":{"description":"Sync drives whether prompt add request should wait and hang until\nthe prompt is done executing. By default the prompt just gets put on a queue\nand the client will just subscribe to a Thread Stream.\nFor quick and dirty scripting however it's often times easier to do things synchronously.\nIn those cases set Sync to true.","type":"boolean"},"threadId":{"description":"ThreadId is the ID of the thread a prompt belongs to.\nClients subscribe to Thread Streams to see the answer to a prompt,\nor set `prompt.sync` to true for a blocking answer.","type":"string"}},"required":["prompt"],"type":"object"}}},"description":"Add Prompt Request","required":true}}
>
  
</RequestSchema>

<StatusCodes
  id={undefined}
  label={undefined}
  responses={{"200":{"description":"OK","content":{"application/json":{"schema":{"properties":{"prompt":{"allOf":[{"properties":{"createdAt":{"description":"CreatedAt is the time of the prompt creation.","type":"string"},"engineParameters":{"allOf":[{"properties":{"llamaCppParameters":{"properties":{"template":{"description":"Template of the prompt. Optional. If not present it's derived from ModelId.","example":"[INST]{prompt}[/INST]","type":"string"}},"type":"object"},"stableDiffusion":{"properties":{"txt2Img":{"allOf":[{"properties":{"alwayson_scripts":{"additionalProperties":{"type":"string"},"type":"object"},"batch_size":{"type":"integer"},"cfg_scale":{"type":"number"},"comments":{"additionalProperties":{"type":"string"},"type":"object"},"denoising_strength":{"type":"number"},"disable_extra_networks":{"type":"boolean"},"do_not_save_grid":{"type":"boolean"},"do_not_save_samples":{"type":"boolean"},"enable_hr":{"type":"boolean"},"eta":{"type":"number"},"firstpass_image":{"type":"string"},"firstphase_height":{"type":"integer"},"firstphase_width":{"type":"integer"},"force_task_id":{"type":"string"},"height":{"type":"integer"},"hr_checkpoint_name":{"type":"string"},"hr_negative_prompt":{"type":"string"},"hr_prompt":{"type":"string"},"hr_resize_x":{"type":"integer"},"hr_resize_y":{"type":"integer"},"hr_sampler_name":{"type":"string"},"hr_scale":{"type":"number"},"hr_scheduler":{"type":"string"},"hr_second_pass_steps":{"type":"integer"},"hr_upscaler":{"type":"string"},"infotext":{"type":"string"},"n_iter":{"type":"integer"},"negative_prompt":{"type":"string"},"override_settings":{"additionalProperties":{"type":"string"},"type":"object"},"override_settings_restore_afterwards":{"type":"boolean"},"prompt":{"type":"string"},"refiner_checkpoint":{"type":"string"},"refiner_switch_at":{"type":"number"},"restore_faces":{"type":"boolean"},"s_churn":{"type":"number"},"s_min_uncond":{"type":"number"},"s_noise":{"type":"number"},"s_tmax":{"type":"number"},"s_tmin":{"type":"number"},"sampler_index":{"type":"string"},"sampler_name":{"type":"string"},"save_images":{"type":"boolean"},"scheduler":{"type":"string"},"script_args":{"items":{"type":"string"},"type":"array"},"script_name":{"type":"string"},"seed":{"type":"integer"},"seed_resize_from_h":{"type":"integer"},"seed_resize_from_w":{"type":"integer"},"send_images":{"type":"boolean"},"steps":{"type":"integer"},"styles":{"items":{"type":"string"},"type":"array"},"subseed":{"type":"integer"},"subseed_strength":{"type":"number"},"tiling":{"type":"boolean"},"width":{"type":"integer"}},"type":"object"}],"description":"Text to image parameters"}},"type":"object"}},"type":"object"}],"description":"AI engine/platform (eg. LlamaCpp, Stable Diffusion) specific parameters"},"error":{"description":"Error that arose during prompt execution, if any.","type":"string"},"id":{"description":"Id is the unique ID of the prompt.","type":"string"},"lastRun":{"description":"LastRun is the time of the last prompt run.","type":"string"},"maxRetries":{"description":"MaxRetries specified how many times the system should retry a prompt when it keeps erroring.","example":10,"type":"integer"},"modelId":{"description":"ModelId is just the OpenOrch internal ID of the model.","example":"huggingface/TheBloke/mistral-7b-instruct-v0.2.Q3_K_S.gguf","type":"string"},"parameters":{"allOf":[{"properties":{"textToImage":{"properties":{"aspectRatio":{"description":"Alternative way to specify dimensions (e.g., \"16:9\", \"1:1\").","type":"string"},"batchSize":{"description":"Number of images to generate per batch.","type":"integer"},"denoisingStrength":{"description":"Controls how much variation is introduced in image modifications.","type":"number"},"enableUpscaling":{"description":"Whether to apply AI-based upscaling.","type":"boolean"},"format":{"description":"Output format for the generated image (png, jpg, webp, etc.).","type":"string"},"guidanceScale":{"description":"How closely the output should follow the prompt.","type":"number"},"height":{"type":"integer"},"negativePrompt":{"description":"A negative prompt to specify what should be avoided in the image.","type":"string"},"numIterations":{"description":"Number of batches to generate.","type":"integer"},"prompt":{"description":"The primary prompt for generating the image.\nDefaults to the top-level prompt if not specified.\nIf both are provided (which should be avoided), this field takes precedence.","type":"string"},"qualityPreset":{"description":"Preset quality settings (e.g., Low, Medium, High, Ultra).","type":"string"},"restoreFaces":{"description":"Whether to enhance facial details for portraits.","type":"boolean"},"scheduler":{"description":"Specifies the sampling method used during generation.","type":"string"},"seed":{"description":"Optional seed for reproducibility. If not set, a random seed is used.","type":"integer"},"steps":{"description":"Number of inference steps for image generation.","type":"integer"},"styles":{"description":"List of artistic styles or themes to apply.","items":{"type":"string"},"type":"array"},"width":{"description":"Image dimensions (width and height in pixels).","type":"integer"}},"type":"object"},"textToText":{"properties":{"template":{"description":"Template of the prompt. Optional. If not present it's derived from ModelId.","example":"[INST]{prompt}[/INST]","type":"string"}},"type":"object"}},"type":"object"}],"description":"AI engine/platform (eg. LlamaCpp, Stable Diffusion) agnostic parameters.\nUse these high level parameters when you don't care about the actual engine, only\nthe functionality (eg. text to image, image to image) it provides."},"prompt":{"description":"Prompt is the message itself eg. \"What's a banana?","example":"What's a banana?","type":"string"},"requestMessageId":{"type":"string"},"responseMessageId":{"type":"string"},"runCount":{"description":"RunCount is the number of times the prompt was retried due to errors","type":"integer"},"status":{"allOf":[{"enum":["scheduled","running","completed","errored","abandoned","canceled"],"type":"string","x-enum-varnames":["PromptStatusScheduled","PromptStatusRunning","PromptStatusCompleted","PromptStatusErrored","PromptStatusAbandoned","PromptStatusCanceled"]}],"description":"Status of the prompt."},"sync":{"description":"Sync drives whether prompt add request should wait and hang until\nthe prompt is done executing. By default the prompt just gets put on a queue\nand the client will just subscribe to a Thread Stream.\nFor quick and dirty scripting however it's often times easier to do things syncronously.\nIn those cases set Sync to true.","type":"boolean"},"threadId":{"description":"ThreadId is the ID of the thread a prompt belongs to.\nClients subscribe to Thread Streams to see the answer to a prompt,\nor set `prompt.sync` to true for a blocking answer.","type":"string"},"type":{"allOf":[{"enum":["Image-Text-to-Text","Visual Question Answering","Document Question Answering","Text-to-Image","Image-to-Image","Image-to-Video","Unconditional Image Generation","Text-to-Video","Zero-Shot Image Classification","Zero-Shot Object Detection","Text-to-3D","Image-to-3D","Image Feature Extraction","Keypoint Detection","Text-to-Text","Question Answering","Translation","Summarization","Text Generation","Fill-Mask","Text-to-Speech","Text-to-Audio","Automatic Speech Recognition","Audio-to-Audio","Audio Classification","Reinforcement Learning","Robotics","Graph Machine Learning"],"type":"string","x-enum-varnames":["PromptTypeImageTextToText","PromptTypeVisualQuestionAnswering","PromptTypeDocumentQuestionAnswering","PromptTypeTextToImage","PromptTypeImageToImage","PromptTypeImageToVideo","PromptTypeUnconditionalImageGeneration","PromptTypeTextToVideo","PromptTypeZeroShotImageClassification","PromptTypeZeroShotObjectDetection","PromptTypeTextTo3D","PromptTypeImageTo3D","PromptTypeImageFeatureExtraction","PromptTypeKeypointDetection","PromptTypeTextToText","PromptTypeQuestionAnswering","PromptTypeTranslation","PromptTypeSummarization","PromptTypeTextGeneration","PromptTypeFillMask","PromptTypeTextToSpeech","PromptTypeTextToAudio","PromptTypeAutomaticSpeechRecognition","PromptTypeAudioToAudio","PromptTypeAudioClassification","PromptTypeReinforcementLearning","PromptTypeRobotics","PromptTypeGraphMachineLearning"]}],"description":"Type is inferred from the `Parameters` or `EngineParameters` field.\nEg. A LLamaCpp prompt will be \"Text-to-Text\",\na Stabel Diffusion one will be \"Text-to-Image\" etc."},"updatedAt":{"description":"UpdatedAt is the last time the prompt was updated.","type":"string"},"userId":{"description":"UserId contains the ID of the user who submitted the prompt.","type":"string"}},"required":["prompt"],"type":"object"}],"description":"Prompt contains the details of the prompt that was just created by this request.\nThis includes the ID, prompt text, status, and other associated metadata."},"responseMessage":{"allOf":[{"properties":{"createdAt":{"type":"string"},"fileIds":{"description":"FileIds defines the file attachments the message has.","items":{"type":"string"},"type":"array"},"id":{"example":"msg_emSOPlW58o","type":"string"},"text":{"description":"Text content of the message eg. \"Hi, what's up?\"","type":"string"},"threadId":{"description":"ThreadId of the message.","example":"thr_emSOeEUWAg","type":"string"},"updatedAt":{"type":"string"},"userId":{"description":"UserId is the id of the user who wrote the message.\nFor AI messages this field is empty.","type":"string"}},"required":["id","threadId"],"type":"object"}],"description":"Response message contains the response text and files.\nThis field is populated only for synchronous prompts (`sync = true`).\nFor asynchronous prompts, the response will provided in the associated\nmessage identified by the `responseMessageId` of the `promptSvc.prompt` object once the prompt completes."}},"type":"object"}}}},"400":{"description":"Invalid JSON","content":{"application/json":{"schema":{"properties":{"error":{"type":"string"}},"type":"object"}}}},"401":{"description":"Unauthorized","content":{"application/json":{"schema":{"properties":{"error":{"type":"string"}},"type":"object"}}}},"500":{"description":"Internal Server Error","content":{"application/json":{"schema":{"properties":{"error":{"type":"string"}},"type":"object"}}}}}}
>
  
</StatusCodes>


      